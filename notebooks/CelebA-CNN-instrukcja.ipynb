{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../materials/title.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color='#58ACFA'> AI Workshop - Część II</font></center>\n",
    "## <center>Wykorzystanie konwolucyjnych sieci neuronowych do klasyfikacji cech twarzy</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#58ACFA'>Plan pracy:</font>\n",
    "\n",
    "#### <font color='#0B3861'> >>> Zbudujemy konwolucyjną sieć neuronową</font>\n",
    "#### <font color='#0B3861'> >>> Przeprowadzimy klasyfikację obrazów ze względu na wybraną cechę</font>\n",
    "#### <font color='#0B3861'> >>> Podglądniemy, które z elementów obrazu zadecydowały o wyniku klasyfikacji</font>\n",
    "\n",
    "### <font color='#0B3861'> Do tego celu posłużymy się danymi pochodzącymi ze zbioru CelebA. Zbiór ten posiada ponad 200 tysięcy zdjęć twarzy znanych celebrytów.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../materials/dataset.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Uwaga: Miejsca w kodzie do uzupełnienia są oznaczone poprzez \"____\"</font>\n",
    "\n",
    "## <font color='#0B3861'>Zaczniemy od zaimportowania niezbędnych bibliotek i ustawienia odpowiednich folderów</font>\n",
    "##### Wykorzystane funkcje zostaną wytłumaczone w dalszej części notatnika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user -r ../requirements.txt # pobieranie bibliotek z pliku requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operacje związane ze ścieżkami\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    " #operacje na macierzach\n",
    "import numpy as np\n",
    "\n",
    "# operacje na danych tabelarycznych\n",
    "import pandas as pd\n",
    "\n",
    "# operacje na obrazach\n",
    "from PIL import Image\n",
    "\n",
    "# wizualizacja postępu wykonania kodu\n",
    "from tqdm import tqdm\n",
    "\n",
    "# tworzenie wykresów i wizualizacja danych\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# importy związane z budową i treningiem modelu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import activations\n",
    "\n",
    "# weryfikacj jakości predykcji\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# wizualizacja map aktywacji klas (CAM)\n",
    "from vis.visualization import visualize_cam, overlay\n",
    "from vis.utils import utils\n",
    "\n",
    "# importy do przykładu ze zdjęciem z internetu\n",
    "from urllib.request import urlopen\n",
    "from resizeimage import resizeimage\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zawsze warto ustawić tak zwane ziarno - określa ono punkt początkowy dla algorytmu generacji liczb pseudolosowych. Dzięki temu przy każdorazowym uruchomieniu notatnika uzyskamy te same wyniki. \n",
    "Podpowiedź: ziarno ustawiamy podając dowolną liczbę do funkcji <font color=red>np.random.seed()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy foldery na zdjęcia i modele\n",
    "dataset_dir = '../img_align_celeba'\n",
    "model_dir = '../models'\n",
    "\n",
    "os.makedirs(dataset_dir,exist_ok=True)\n",
    "os.makedirs(model_dir,exist_ok=True)\n",
    "\n",
    "labels_path = '../list_attr_celeba.txt'\n",
    "landmarks_path = '../list_landmarks_align_celeba.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#0B3861'>Pobranie i rozpakowanie danych</font>\n",
    "### Uwaga: Dane obrazowe zostały już przygotowane\n",
    "*   <font color='red'>Linux</font>  \n",
    "Dane obrazowe:\n",
    "```bash\n",
    "!wget https://www.dropbox.com/s/lpmjzzk26nae9bh/img_align_celeba.zip -P ./..\n",
    "!unzip -q -d ../img_align_celeba ../img_align_celeba.zip\n",
    "```\n",
    "Dane liczbowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/qpjuy9isvm19xsv/list_attr_celeba.txt -P ./.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Windows  \n",
    "Pobierz pliki ze strony dropbox i wypakuj plik zip wybranym programem do obsługi archiwów.\n",
    "https://www.dropbox.com/s/lpmjzzk26nae9bh/img_align_celeba.zip  \n",
    "https://www.dropbox.com/s/qpjuy9isvm19xsv/list_attr_celeba.txt  \n",
    "https://www.dropbox.com/s/lmc2ywmuk6c29tt/list_landmarks_align_celeba.txt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#0B3861'>Wczytanie i przygotowanie danych</font>\n",
    "#### Etykiety dotyczące cech twarzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = []\n",
    "with open(labels_path, 'r') as f:\n",
    "    f.readline()\n",
    "    attribute_names = ['fn']+f.readline().strip().split(' ')\n",
    "    for i, line in enumerate(f):\n",
    "        fields = line.strip().replace('  ', ' ').split(' ')\n",
    "        img_name = fields[0]\n",
    "        if int(img_name[:6]) != i + 1:\n",
    "            raise ValueError('Parse error.')\n",
    "        attr_vec = np.array([fields[0]]+[int(x) for x in fields[1:]])\n",
    "        attributes.append(attr_vec)\n",
    "        \n",
    "attributes = np.array(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stworzenie tabeli z cechami i etykietami\n",
    "#### 1 - cecha obecna na obrazie\n",
    "#### -1 - brak cechy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=attributes, columns=attribute_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyświetl listę wszystkich dostępnych cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df.columns[1:]:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wybranie cechy badanej na warsztatach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examined_feature = 'Bald'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W celu przyspieszenia obliczeń wykorzystamy jedynie 10 000 losowo wybranych obrazów. Potrzebujemy zatem 10000 losowo wybranych indeksów, ale w taki sposób, żeby wśród wybranych przykładów nasza cecha pojawiła się w mniej więcej połowie przypadków.\n",
    "\n",
    "#### W tym celu wykorzystamy funkcję <font color='red'>df.groupby()</font> która przyjmuje nazwę wybranej cechy (examined_feature) do pogrupowania rekordów według tej cechy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = ____(____) # pogrupuj rekordy według badanej cechy\n",
    "n_samples = np.min([10000//2,df_balanced.size().min()])\n",
    "\n",
    "print(n_samples) # wyświetlenie ilości przykładów zawierających naszą cechę"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stworzenie tabeli tylko z wybranymi przykładami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wybranie próbki dla każdej z wartości etykiet binarnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df_balanced.apply(lambda x: x.sample(n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ustaw kolumnę 'fn' jako indeks za pomocą <font color='red'>df.set_index()</font> i pozostaw jedynie kolumnę z interesującą nas cechą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df_balanced.____(____)[examined_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przekształcenie obiektu po grupowaniu z powrotem do tabeli i kolejny restart indeksu w celu uzyskania 'fn' jako osobnej kolumny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = (df_balanced.to_frame()[examined_feature]).reset_index() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metoda <font color='red'> df.head(n=5)</font> pozwala na wyświetlenie pierwszych 5 wierszy tabeli. Wyświetl 20 pierwszych wierszy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.____(____) # wyświetl 20 pierwszych wierszy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Całkowita ilość wybranych obrazów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mamy',str(len(df_balanced)),'obrazów')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie etykiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (df_balanced[examined_feature].values) == '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sprawdź ilość przykładów zawierających naszą cechę oraz ilość przykładów bez tej cechy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(labels==True),np.sum(labels==False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie i przygotowanie obrazów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Razem z wczytaniem danych  (<font color='red'>Image.open()</font>) przygotujemy je do wykorzystania: przytniemy krawędzie (<font color='red'>crop()</font>) i zmniejszymy ich rozmiar (<font color='red'>resize()</font>), co znacznie przyspieszy trening modelu.\n",
    "#### Zastosuj wylosowane indeksy w celu wczytania zbioru danych do pracy. Przytnij obraz wprowadzając wartości 9, 13, 169 i 205 (koordynaty pikseli) w odpowednie miejsce. Następnie zmniejsz obraz do rozmiaru 80x96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(\n",
    "        [np.array(Image.open(os.path.join(dataset_dir,x['fn'])).\n",
    "                  crop(box=(____)).resize((____)))\n",
    "         for i,x in tqdm(df_balanced.iterrows())]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Żeby upewnić się, że wszystko poszło dobrze, wyświetl wymiary obrazów "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyświetl przykładowe obrazy osób bez wybranej cechy oraz osób posiadających daną cechę\n",
    "##### Ustaw wielkość figur na 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(____,____))\n",
    "for i in range(1,10):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.title(examined_feature if labels[i]==1 else '~'+examined_feature)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.squeeze(images[i]))\n",
    "plt.show()\n",
    "plt.figure(figsize=(____,____))\n",
    "for i in range(1,10):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.title(examined_feature if labels[len(labels) - i]==1 else '~'+examined_feature)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.squeeze(images[len(labels) - i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#0B3861'>Budowa modelu konwolucyjnej sieci neuronowej (CNN)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na początku zdefiniujemy parametry określające model CNN i jego trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = images.shape[1:4] #wielkość obrazu wejściowego, wykorzystywana dla budowy grafu SN\n",
    "\n",
    "\"\"\" Parametry określające trening modelu \"\"\"\n",
    "batch_size = 128 # liczba obrazów wykorzystywana do jednego kroku treningu SN\n",
    "optimizer = 'adam' # funkcja odpowiadająca za redukcję błędu sieci\n",
    "loss_fn = 'sparse_categorical_crossentropy' # funkcja służąca do obliczenia o ile różni się wartość oczekiwana od otrzymanej na wyjściu SN\n",
    "epochs = 30 # maksymalna liczba epok, czyli ile razy sieć będzie widziała dane treningowe\n",
    "model_path = os.path.join(model_dir,'celeb_cnn_v2_'+examined_feature+'.h5') # ustawienie ścieżki do pliku z modelem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Na podstawie poniższego schematu i wskazówek zbuduj model konwolucyjnej sieci neuronowej (uzupełnij brakujące części kodu) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../materials/cnn.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../materials/cnn_legenda.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Ważne wskazówki </font>:\n",
    "*   Zwróć uwagę na kolory warstw na powyższym schemacie i nazwy w nawiasach\n",
    "*   Brakujące warstwy uzupełniaj analogicznie do wpisanych już przykładów\n",
    "*   Uzupełnij brakujące pola \"____\" w wyznaczonych miejscach\n",
    "*   Funkcja aktywacji to <font color='red'>'relu'</font> (za wyjątkiem ostatniej, gdzie jest 'softmax')\n",
    "*   Dla każdej kolejnej warstwy konwolucyjnej liczbę filtrów <font color='red'>zwiększ dwukrotnie w stosunku do poprzedniej</font> \n",
    "*   Dla każdej warstwy konwolucyjnej ustaw wielkość filtru <font color='red'>3x3</font>\n",
    "*   Dla każdej warstwy głosującej ustaw wielkość filtru <font color='red'>2x2</font>\n",
    "*   Dla każdej warstwy Dropout (z wyjątkiem ostatniej) <font color='red'>25%</font> neuronów zostaje wyłączona "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_shape, name='input')\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = ____(____)(x)\n",
    "x = ____(____)(x)\n",
    "x = ____(____)(x)\n",
    "\n",
    "x = ____(____)(x)\n",
    "x = ____(____)(x)\n",
    "x = ____(____)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = ____(256, activation=____)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = ____(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=x, name='CNN')\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#0B3861'>Trening konwolucyjnej sieci neuronowej</font>\n",
    "\n",
    "### Podział danych na testowe i treningowe\n",
    "#### Podział danych jest realizowany za pomocą funkcji <font color='red'>train_test_split</font>, która przyjmuje dane do podziału, ich etykiety oraz procent przykładów które będą przydzielone do zbioru testowego <font color='red'>test_size</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ____(images.astype('float32')/255, labels, ____=0.2) # uzupełnij kod do podziału danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Powyższa funkcja wyprodukowała 4 zmienne: X_train i X_test zawierające odpowiednio dane treningowe i testowe oraz y_train, y_test będące etykietami dla każdego z przykładów w zbiorach danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standaryzacja danych\n",
    "#### Dokończ standaryzowanie obrazów, w każdym z kanałów RGB (3), wykorzystując funkcje biblioteki numpy wyliczające średnią i odchylenie standardowe (<font color='red'>np.mean(), np.std()</font>) oraz poniższy wzór:\n",
    "\\begin{equation}\n",
    "X = \\frac{X - mean(X)}{std(X)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = []\n",
    "X_std = []\n",
    "for i in range(3):\n",
    "    # zapisanie średnich i odchyleń z danych - będą potrzebne później\n",
    "    X_mean.append(np.mean(X_train[:,:,:,i]))\n",
    "    X_std.append(np.std(X_train[:,:,:,i]))\n",
    "    \n",
    "    # uzupełnij poniższe wzory standaryzujące dane treningowe i testowe\n",
    "    X_train[:,:,:,i] = (X_train[:,:,:,i] - ____(____))/____(____)\n",
    "    X_test[:,:,:,i] = (X_test[:,:,:,i] - ____(____))/____(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wprowadzenie parametrów treningowych i funkcji monitorujących przebieg treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(restore_best_weights=True, patience=3) # zatrzyma uczenie jeśli nie będzie poprawy przez 3 epoki\n",
    "checkpt = ModelCheckpoint(model_path, save_best_only=True, save_weights_only=True) # zapisze wagi dla najlepszej epoki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening CNN\n",
    "#### Dopisz w odpowiednich miejscach brakujące dane i etykiety (dane testowe jako walidacyjne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, ____,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_data=(____, y_test),\n",
    "                  verbose=2,\n",
    "                  callbacks = [early_stop, checkpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#0B3861'>Weryfikacja rezultatów</font>\n",
    "#### Wczytanie zapisanych wag z epoki, dla której wartość funkcji straty była najniższa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weryfikacja jakości predykcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred)) # macierz błędów klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(____, ____)) # uzupełnij raport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#0B3861'>Wizualizacja CAM</font>\n",
    "\n",
    "### CAMy to mapy cieplne wskazujące obszary obrazu, które przyczyniły się najbardziej do wyniku klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wymagane modyfikacje\n",
    "model_vis = model\n",
    "model_vis.layers[-1].activation = activations.linear\n",
    "model_vis = utils.apply_modifications(model_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(1,10):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.title(examined_feature if labels[i]==1 else '~'+examined_feature)\n",
    "    grads = visualize_cam(model_vis, -1, filter_indices=int(labels[i]), \n",
    "                          seed_input=images[i], backprop_modifier='guided')    \n",
    "    plt.imshow(overlay(cm.jet(grads)[:,:,:3], images[i]/255))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(1,10):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.title(examined_feature if labels[len(labels) - i]==1 else '~'+examined_feature)\n",
    "    grads = visualize_cam(model_vis, -1, filter_indices=int(labels[[len(labels) - i]]), \n",
    "                          seed_input=images[len(labels) - i], backprop_modifier='guided')    \n",
    "    plt.imshow(overlay(cm.jet(grads)[:,:,:3], images[len(labels) - i]/255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#58ACFA'>>>> Co można wywnioskować na podstawie uzyskanych wizualizacji CAMów?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#0B3861'>Sprawdzenie działania na zdjęciu spoza zbioru danych - przykład z internetu</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(urlopen('http://www.afternoondc.in/Thumbnails.aspx?Filename=2018319214726.jpg'))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wyświetl rozmiar obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Za pomocą funkcji <font color='red'>resizeimage.resize_cover</font> zmniejsz obraz do rozmiaru <font color='red'>80x96</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ____(img, [____, ____])\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przetworzenie obrazu do formy akceptowanej przez sieć neuronową"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_float = np.array(img).astype(np.float32)\n",
    "img_std = img_float.copy()\n",
    "for i in range(3):\n",
    "    img_std[:,:,i] = (img_std[:,:,i]-X_mean[i])/X_std[i]\n",
    "img_std = np.expand_dims(img_std,0)\n",
    "\n",
    "img_std.shape # wyświetlenie końcowych wymiarów obrazu (po przetworzeniu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predykcja sieci neuronowej dla przygotowanego obrazu za pomocą <font color='red'>predict()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = model.____(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizualizacja CAM dla obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = visualize_cam(model_vis, -1, filter_indices=1, \n",
    "                      seed_input=np.squeeze(img_std), backprop_modifier='guided')    \n",
    "plt.imshow(overlay(cm.jet(grads)[:,:,:3], img_float/255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#0B3861'>Twój przykład. Znajdź obraz na internecie i sprawdź odpowiedź sieci neuronowej :)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from resizeimage import resizeimage\n",
    "\n",
    "img = Image.open(urlopen(' tutaj link do obrazka '))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ____(img, [____, ____]) # zmniejszenie rozmiaru resizeimage.resize_cover\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_float = np.array(img).astype(np.float32)\n",
    "img_std = img_float.copy()\n",
    "for i in range(3):\n",
    "    img_std[:,:,i] = (img_std[:,:,i]-X_mean[i])/X_std[i]\n",
    "img_std = np.expand_dims(img_std,0)\n",
    "img_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = model.____(____) # predykcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = visualize_cam(model_vis, -1, filter_indices=1, \n",
    "                      seed_input=np.squeeze(img_std), backprop_modifier='guided')    \n",
    "plt.imshow(overlay(cm.jet(grads)[:,:,:3], img_float/255))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
